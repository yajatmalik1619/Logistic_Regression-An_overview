from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

def basic_classification_report(y_true, y_pred, y_prob=None):
    report = {
        "accuracy": accuracy_score(y_true, y_pred),
        "precision": precision_score(y_true, y_pred, zero_division=0),
        "recall": recall_score(y_true, y_pred, zero_division=0),
        "f1": f1_score(y_true, y_pred, zero_division=0),
    }
    if y_prob is not None:
        try:
            report["roc_auc"] = roc_auc_score(y_true, y_prob)
        except Exception:
            report["roc_auc"] = None
    report["confusion_matrix"] = confusion_matrix(y_true, y_pred).tolist()
    return report
